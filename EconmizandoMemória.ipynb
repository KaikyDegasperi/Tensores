{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSR782a++1G8t9GF1S4F/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaikyDegasperi/Tensores/blob/main/EconmizandoMem%C3%B3ria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy\n",
        "\n",
        "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTgxTaAcwTpk",
        "outputId": "e4c062c5-db18-49d4-92b1-c821d233b1e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.],\n",
              "         [ 4.,  3.,  2.,  1.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversão para Outros Objetos Python\n",
        "\n",
        "Converter para um tensor NumPy (ndarray), ou vice-versa, é fácil. O tensor torch e o array NumPy compartilharão sua memória subjacente, e modificar um deles através de uma operação no local também modificará o outro.\n"
      ],
      "metadata": {
        "id": "As-EeJF5wLPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcmaXdARwISr",
        "outputId": "74a47f16-6820-4097-eb44-feb213c59674"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Economizando Memória\n",
        "\n",
        "Executar operações pode causar a alocação de nova memória para armazenar os resultados. Por exemplo, se escrevemos Y = X + Y, desreferenciamos o tensor para o qual Y costumava apontar e, em vez disso, apontamos Y para a nova memória alocada. Podemos demonstrar esse problema com a função id() do Python, que nos dá o endereço exato do objeto referenciado na memória. Note que depois de executarmos Y = Y + X, id(Y) aponta para um local diferente. Isso ocorre porque o Python primeiro avalia Y + X, alocando nova memória para o resultado, e depois aponta Y para esse novo local na memória.\n"
      ],
      "metadata": {
        "id": "_acJUrRUrFbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_WvSoVtq-gR",
        "outputId": "2e6baaf7-7002-4375-8e11-503559e7cd7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ]
    }
  ]
}